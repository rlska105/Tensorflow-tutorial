{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 1, 손실 함수(Loss): 0.066458\n",
      "반복(Epoch): 2, 손실 함수(Loss): 0.053417\n",
      "반복(Epoch): 3, 손실 함수(Loss): 0.048841\n",
      "반복(Epoch): 4, 손실 함수(Loss): 0.051335\n",
      "반복(Epoch): 5, 손실 함수(Loss): 0.046059\n",
      "반복(Epoch): 6, 손실 함수(Loss): 0.039696\n",
      "반복(Epoch): 7, 손실 함수(Loss): 0.035320\n",
      "반복(Epoch): 8, 손실 함수(Loss): 0.035885\n",
      "반복(Epoch): 9, 손실 함수(Loss): 0.041328\n",
      "반복(Epoch): 10, 손실 함수(Loss): 0.035479\n",
      "반복(Epoch): 11, 손실 함수(Loss): 0.033553\n",
      "반복(Epoch): 12, 손실 함수(Loss): 0.034147\n",
      "반복(Epoch): 13, 손실 함수(Loss): 0.036413\n",
      "반복(Epoch): 14, 손실 함수(Loss): 0.030665\n",
      "반복(Epoch): 15, 손실 함수(Loss): 0.033856\n",
      "반복(Epoch): 16, 손실 함수(Loss): 0.031700\n",
      "반복(Epoch): 17, 손실 함수(Loss): 0.028617\n",
      "반복(Epoch): 18, 손실 함수(Loss): 0.030114\n",
      "반복(Epoch): 19, 손실 함수(Loss): 0.032127\n",
      "반복(Epoch): 20, 손실 함수(Loss): 0.027194\n",
      "반복(Epoch): 21, 손실 함수(Loss): 0.027256\n",
      "반복(Epoch): 22, 손실 함수(Loss): 0.031238\n",
      "반복(Epoch): 23, 손실 함수(Loss): 0.028044\n",
      "반복(Epoch): 24, 손실 함수(Loss): 0.025758\n",
      "반복(Epoch): 25, 손실 함수(Loss): 0.027937\n",
      "반복(Epoch): 26, 손실 함수(Loss): 0.025885\n",
      "반복(Epoch): 27, 손실 함수(Loss): 0.026314\n",
      "반복(Epoch): 28, 손실 함수(Loss): 0.029495\n",
      "반복(Epoch): 29, 손실 함수(Loss): 0.028667\n",
      "반복(Epoch): 30, 손실 함수(Loss): 0.026648\n",
      "반복(Epoch): 31, 손실 함수(Loss): 0.024579\n",
      "반복(Epoch): 32, 손실 함수(Loss): 0.020578\n",
      "반복(Epoch): 33, 손실 함수(Loss): 0.022749\n",
      "반복(Epoch): 34, 손실 함수(Loss): 0.026951\n",
      "반복(Epoch): 35, 손실 함수(Loss): 0.024370\n",
      "반복(Epoch): 36, 손실 함수(Loss): 0.020968\n",
      "반복(Epoch): 37, 손실 함수(Loss): 0.025648\n",
      "반복(Epoch): 38, 손실 함수(Loss): 0.023682\n",
      "반복(Epoch): 39, 손실 함수(Loss): 0.024543\n",
      "반복(Epoch): 40, 손실 함수(Loss): 0.021416\n",
      "반복(Epoch): 41, 손실 함수(Loss): 0.022243\n",
      "반복(Epoch): 42, 손실 함수(Loss): 0.023231\n",
      "반복(Epoch): 43, 손실 함수(Loss): 0.021101\n",
      "반복(Epoch): 44, 손실 함수(Loss): 0.025896\n",
      "반복(Epoch): 45, 손실 함수(Loss): 0.023574\n",
      "반복(Epoch): 46, 손실 함수(Loss): 0.021670\n",
      "반복(Epoch): 47, 손실 함수(Loss): 0.025315\n",
      "반복(Epoch): 48, 손실 함수(Loss): 0.023511\n",
      "반복(Epoch): 49, 손실 함수(Loss): 0.023795\n",
      "반복(Epoch): 50, 손실 함수(Loss): 0.022274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimginam/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:79: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "/Users/kimginam/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:81: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "\n",
    "# 학습에 필요한 설정값들을 정의합니다.\n",
    "learning_rate = 0.02\n",
    "training_epochs = 50    # 반복횟수\n",
    "batch_size = 256        # 배치개수\n",
    "display_step = 1        # 손실함수 출력 주기\n",
    "examples_to_show = 10   # 보여줄 MNIST Reconstruction 이미지 개수\n",
    "input_size = 784        # 28*28\n",
    "hidden1_size = 256\n",
    "hidden2_size = 128\n",
    "\n",
    "# tf.data API를 이용해서 데이터를 섞고 batch 형태로 가져옵니다.\n",
    "train_data = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_data = train_data.shuffle(60000).batch(batch_size)\n",
    "\n",
    "# Autoencoder 모델을 정의합니다.\n",
    "class AutoEncoder(object):\n",
    "    # Autoencoder 모델을 위한 tf.Variable들을 정의합니다.\n",
    "    def __init__(self):\n",
    "        # 인코딩(Encoding) - 784 -> 256 -> 128\n",
    "        self.W1 = tf.Variable(tf.random.normal(shape=[input_size, hidden1_size]))\n",
    "        self.b1 = tf.Variable(tf.random.normal(shape=[hidden1_size]))\n",
    "        self.W2 = tf.Variable(tf.random.normal(shape=[hidden1_size, hidden2_size]))\n",
    "        self.b2 = tf.Variable(tf.random.normal(shape=[hidden2_size]))\n",
    "        # 디코딩(Decoding) 128 -> 256 -> 784\n",
    "        self.W3 = tf.Variable(tf.random.normal(shape=[hidden2_size, hidden1_size]))\n",
    "        self.b3 = tf.Variable(tf.random.normal(shape=[hidden1_size]))\n",
    "        self.W4 = tf.Variable(tf.random.normal(shape=[hidden1_size, input_size]))\n",
    "        self.b4 = tf.Variable(tf.random.normal(shape=[input_size]))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        H1_output = tf.nn.sigmoid(tf.matmul(x, self.W1) + self.b1)\n",
    "        H2_output = tf.nn.sigmoid(tf.matmul(H1_output, self.W2) + self.b2)\n",
    "        H3_output = tf.nn.sigmoid(tf.matmul(H2_output, self.W3) + self.b3)\n",
    "        reconstructed_x = tf.nn.sigmoid(tf.matmul(H3_output, self.W4) + self.b4)\n",
    "\n",
    "        return reconstructed_x\n",
    "\n",
    "# MSE 손실 함수를 정의합니다.\n",
    "@tf.function\n",
    "def mse_loss(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.pow(y_true - y_pred, 2)) # MSE(Mean of Squared Error) 손실함수\n",
    "\n",
    "# 최적화를 위한 RMSProp 옵티마이저를 정의합니다.\n",
    "optimizer = tf.optimizers.RMSprop(learning_rate)\n",
    "\n",
    "# 최적화를 위한 function을 정의합니다.\n",
    "@tf.function\n",
    "def train_step(model, x):\n",
    "    y_true = x\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        loss = mse_loss(y_pred, y_true)\n",
    "    gradients = tape.gradient(loss, vars(model).values())\n",
    "    optimizer.apply_gradients(zip(gradients, vars(model).values()))\n",
    "\n",
    "AutoEncoder_model = AutoEncoder()\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    for batch_x in train_data:\n",
    "        _, current_loss = train_step(AutoEncoder_model, batch_x), mse_loss(AutoEncoder_model(batch_x), batch_x)\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"반복(Epoch): %d, 손실 함수(Loss): %f\" % ((epoch+1), current_loss))\n",
    "\n",
    "reconstructed_result = AutoEncoder_model(x_test[:examples_to_show])\n",
    "f, a = plt.subplots(2, 10, figsize=(10, 2))\n",
    "for i in range(examples_to_show):\n",
    "    a[0][i].imshow(np.reshape(x_test[i], (28, 28)))\n",
    "    a[1][i].imshow(np.reshape(reconstructed_result[i], (28, 28)))\n",
    "f.savefig('reconstructed_mnist_image.png')  # reconstruction 결과를 png로 저장합니다.\n",
    "f.show()\n",
    "plt.draw()\n",
    "plt.waitforbuttonpress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
