{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 1, Pre-Training 손실 함수(pretraining_loss): 0.049743\n",
      "반복(Epoch): 2, Pre-Training 손실 함수(pretraining_loss): 0.042911\n",
      "반복(Epoch): 3, Pre-Training 손실 함수(pretraining_loss): 0.037840\n",
      "반복(Epoch): 4, Pre-Training 손실 함수(pretraining_loss): 0.036213\n",
      "반복(Epoch): 5, Pre-Training 손실 함수(pretraining_loss): 0.034457\n",
      "반복(Epoch): 6, Pre-Training 손실 함수(pretraining_loss): 0.030195\n",
      "반복(Epoch): 7, Pre-Training 손실 함수(pretraining_loss): 0.031549\n",
      "반복(Epoch): 8, Pre-Training 손실 함수(pretraining_loss): 0.030624\n",
      "반복(Epoch): 9, Pre-Training 손실 함수(pretraining_loss): 0.030509\n",
      "반복(Epoch): 10, Pre-Training 손실 함수(pretraining_loss): 0.032453\n",
      "반복(Epoch): 11, Pre-Training 손실 함수(pretraining_loss): 0.027803\n",
      "반복(Epoch): 12, Pre-Training 손실 함수(pretraining_loss): 0.027496\n",
      "반복(Epoch): 13, Pre-Training 손실 함수(pretraining_loss): 0.030047\n",
      "반복(Epoch): 14, Pre-Training 손실 함수(pretraining_loss): 0.025582\n",
      "반복(Epoch): 15, Pre-Training 손실 함수(pretraining_loss): 0.026658\n",
      "반복(Epoch): 16, Pre-Training 손실 함수(pretraining_loss): 0.027495\n",
      "반복(Epoch): 17, Pre-Training 손실 함수(pretraining_loss): 0.022588\n",
      "반복(Epoch): 18, Pre-Training 손실 함수(pretraining_loss): 0.029574\n",
      "반복(Epoch): 19, Pre-Training 손실 함수(pretraining_loss): 0.023849\n",
      "반복(Epoch): 20, Pre-Training 손실 함수(pretraining_loss): 0.021428\n",
      "반복(Epoch): 21, Pre-Training 손실 함수(pretraining_loss): 0.026461\n",
      "반복(Epoch): 22, Pre-Training 손실 함수(pretraining_loss): 0.025387\n",
      "반복(Epoch): 23, Pre-Training 손실 함수(pretraining_loss): 0.021426\n",
      "반복(Epoch): 24, Pre-Training 손실 함수(pretraining_loss): 0.021372\n",
      "반복(Epoch): 25, Pre-Training 손실 함수(pretraining_loss): 0.022292\n",
      "반복(Epoch): 26, Pre-Training 손실 함수(pretraining_loss): 0.023740\n",
      "반복(Epoch): 27, Pre-Training 손실 함수(pretraining_loss): 0.019361\n",
      "반복(Epoch): 28, Pre-Training 손실 함수(pretraining_loss): 0.019228\n",
      "반복(Epoch): 29, Pre-Training 손실 함수(pretraining_loss): 0.018900\n",
      "반복(Epoch): 30, Pre-Training 손실 함수(pretraining_loss): 0.017810\n",
      "반복(Epoch): 31, Pre-Training 손실 함수(pretraining_loss): 0.021159\n",
      "반복(Epoch): 32, Pre-Training 손실 함수(pretraining_loss): 0.020024\n",
      "반복(Epoch): 33, Pre-Training 손실 함수(pretraining_loss): 0.018845\n",
      "반복(Epoch): 34, Pre-Training 손실 함수(pretraining_loss): 0.017796\n",
      "반복(Epoch): 35, Pre-Training 손실 함수(pretraining_loss): 0.018869\n",
      "반복(Epoch): 36, Pre-Training 손실 함수(pretraining_loss): 0.016123\n",
      "반복(Epoch): 37, Pre-Training 손실 함수(pretraining_loss): 0.017240\n",
      "반복(Epoch): 38, Pre-Training 손실 함수(pretraining_loss): 0.015720\n",
      "반복(Epoch): 39, Pre-Training 손실 함수(pretraining_loss): 0.018001\n",
      "반복(Epoch): 40, Pre-Training 손실 함수(pretraining_loss): 0.015367\n",
      "반복(Epoch): 41, Pre-Training 손실 함수(pretraining_loss): 0.015309\n",
      "반복(Epoch): 42, Pre-Training 손실 함수(pretraining_loss): 0.015421\n",
      "반복(Epoch): 43, Pre-Training 손실 함수(pretraining_loss): 0.014992\n",
      "반복(Epoch): 44, Pre-Training 손실 함수(pretraining_loss): 0.014980\n",
      "반복(Epoch): 45, Pre-Training 손실 함수(pretraining_loss): 0.013432\n",
      "반복(Epoch): 46, Pre-Training 손실 함수(pretraining_loss): 0.013857\n",
      "반복(Epoch): 47, Pre-Training 손실 함수(pretraining_loss): 0.016275\n",
      "반복(Epoch): 48, Pre-Training 손실 함수(pretraining_loss): 0.013217\n",
      "반복(Epoch): 49, Pre-Training 손실 함수(pretraining_loss): 0.013918\n",
      "반복(Epoch): 50, Pre-Training 손실 함수(pretraining_loss): 0.014385\n",
      "반복(Epoch): 51, Pre-Training 손실 함수(pretraining_loss): 0.012697\n",
      "반복(Epoch): 52, Pre-Training 손실 함수(pretraining_loss): 0.014767\n",
      "반복(Epoch): 53, Pre-Training 손실 함수(pretraining_loss): 0.014390\n",
      "반복(Epoch): 54, Pre-Training 손실 함수(pretraining_loss): 0.013820\n",
      "반복(Epoch): 55, Pre-Training 손실 함수(pretraining_loss): 0.013112\n",
      "반복(Epoch): 56, Pre-Training 손실 함수(pretraining_loss): 0.014045\n",
      "반복(Epoch): 57, Pre-Training 손실 함수(pretraining_loss): 0.013252\n",
      "반복(Epoch): 58, Pre-Training 손실 함수(pretraining_loss): 0.013557\n",
      "반복(Epoch): 59, Pre-Training 손실 함수(pretraining_loss): 0.012789\n",
      "반복(Epoch): 60, Pre-Training 손실 함수(pretraining_loss): 0.014036\n",
      "반복(Epoch): 61, Pre-Training 손실 함수(pretraining_loss): 0.012991\n",
      "반복(Epoch): 62, Pre-Training 손실 함수(pretraining_loss): 0.010917\n",
      "반복(Epoch): 63, Pre-Training 손실 함수(pretraining_loss): 0.013683\n",
      "반복(Epoch): 64, Pre-Training 손실 함수(pretraining_loss): 0.011623\n",
      "반복(Epoch): 65, Pre-Training 손실 함수(pretraining_loss): 0.012471\n",
      "반복(Epoch): 66, Pre-Training 손실 함수(pretraining_loss): 0.012098\n",
      "반복(Epoch): 67, Pre-Training 손실 함수(pretraining_loss): 0.012678\n",
      "반복(Epoch): 68, Pre-Training 손실 함수(pretraining_loss): 0.012206\n",
      "반복(Epoch): 69, Pre-Training 손실 함수(pretraining_loss): 0.011837\n",
      "반복(Epoch): 70, Pre-Training 손실 함수(pretraining_loss): 0.013574\n",
      "반복(Epoch): 71, Pre-Training 손실 함수(pretraining_loss): 0.011685\n",
      "반복(Epoch): 72, Pre-Training 손실 함수(pretraining_loss): 0.010747\n",
      "반복(Epoch): 73, Pre-Training 손실 함수(pretraining_loss): 0.011667\n",
      "반복(Epoch): 74, Pre-Training 손실 함수(pretraining_loss): 0.012058\n",
      "반복(Epoch): 75, Pre-Training 손실 함수(pretraining_loss): 0.013249\n",
      "반복(Epoch): 76, Pre-Training 손실 함수(pretraining_loss): 0.010334\n",
      "반복(Epoch): 77, Pre-Training 손실 함수(pretraining_loss): 0.013030\n",
      "반복(Epoch): 78, Pre-Training 손실 함수(pretraining_loss): 0.012040\n",
      "반복(Epoch): 79, Pre-Training 손실 함수(pretraining_loss): 0.012203\n",
      "반복(Epoch): 80, Pre-Training 손실 함수(pretraining_loss): 0.012027\n",
      "반복(Epoch): 81, Pre-Training 손실 함수(pretraining_loss): 0.009763\n",
      "반복(Epoch): 82, Pre-Training 손실 함수(pretraining_loss): 0.012168\n",
      "반복(Epoch): 83, Pre-Training 손실 함수(pretraining_loss): 0.012975\n",
      "반복(Epoch): 84, Pre-Training 손실 함수(pretraining_loss): 0.011691\n",
      "반복(Epoch): 85, Pre-Training 손실 함수(pretraining_loss): 0.010387\n",
      "반복(Epoch): 86, Pre-Training 손실 함수(pretraining_loss): 0.010885\n",
      "반복(Epoch): 87, Pre-Training 손실 함수(pretraining_loss): 0.010837\n",
      "반복(Epoch): 88, Pre-Training 손실 함수(pretraining_loss): 0.010002\n",
      "반복(Epoch): 89, Pre-Training 손실 함수(pretraining_loss): 0.011164\n",
      "반복(Epoch): 90, Pre-Training 손실 함수(pretraining_loss): 0.010892\n",
      "반복(Epoch): 91, Pre-Training 손실 함수(pretraining_loss): 0.010887\n",
      "반복(Epoch): 92, Pre-Training 손실 함수(pretraining_loss): 0.010240\n",
      "반복(Epoch): 93, Pre-Training 손실 함수(pretraining_loss): 0.010769\n",
      "반복(Epoch): 94, Pre-Training 손실 함수(pretraining_loss): 0.010685\n",
      "반복(Epoch): 95, Pre-Training 손실 함수(pretraining_loss): 0.010019\n",
      "반복(Epoch): 96, Pre-Training 손실 함수(pretraining_loss): 0.012695\n",
      "반복(Epoch): 97, Pre-Training 손실 함수(pretraining_loss): 0.010058\n",
      "반복(Epoch): 98, Pre-Training 손실 함수(pretraining_loss): 0.009547\n",
      "반복(Epoch): 99, Pre-Training 손실 함수(pretraining_loss): 0.011146\n",
      "반복(Epoch): 100, Pre-Training 손실 함수(pretraining_loss): 0.010217\n",
      "Step 1 : MNIST 데이터 재구축을 위한 오토인코더 최적화 완료(Pre-Training)\n",
      "반복(Epoch): 1, Fine-tuning 손실 함수(finetuning_loss): 0.375120\n",
      "반복(Epoch): 2, Fine-tuning 손실 함수(finetuning_loss): 0.284021\n",
      "반복(Epoch): 3, Fine-tuning 손실 함수(finetuning_loss): 0.278725\n",
      "반복(Epoch): 4, Fine-tuning 손실 함수(finetuning_loss): 0.271260\n",
      "반복(Epoch): 5, Fine-tuning 손실 함수(finetuning_loss): 0.211551\n",
      "반복(Epoch): 6, Fine-tuning 손실 함수(finetuning_loss): 0.197465\n",
      "반복(Epoch): 7, Fine-tuning 손실 함수(finetuning_loss): 0.124732\n",
      "반복(Epoch): 8, Fine-tuning 손실 함수(finetuning_loss): 0.215331\n",
      "반복(Epoch): 9, Fine-tuning 손실 함수(finetuning_loss): 0.111310\n",
      "반복(Epoch): 10, Fine-tuning 손실 함수(finetuning_loss): 0.141969\n",
      "반복(Epoch): 11, Fine-tuning 손실 함수(finetuning_loss): 0.140323\n",
      "반복(Epoch): 12, Fine-tuning 손실 함수(finetuning_loss): 0.167370\n",
      "반복(Epoch): 13, Fine-tuning 손실 함수(finetuning_loss): 0.069784\n",
      "반복(Epoch): 14, Fine-tuning 손실 함수(finetuning_loss): 0.141189\n",
      "반복(Epoch): 15, Fine-tuning 손실 함수(finetuning_loss): 0.109541\n",
      "반복(Epoch): 16, Fine-tuning 손실 함수(finetuning_loss): 0.096034\n",
      "반복(Epoch): 17, Fine-tuning 손실 함수(finetuning_loss): 0.151084\n",
      "반복(Epoch): 18, Fine-tuning 손실 함수(finetuning_loss): 0.178155\n",
      "반복(Epoch): 19, Fine-tuning 손실 함수(finetuning_loss): 0.131444\n",
      "반복(Epoch): 20, Fine-tuning 손실 함수(finetuning_loss): 0.102025\n",
      "반복(Epoch): 21, Fine-tuning 손실 함수(finetuning_loss): 0.325582\n",
      "반복(Epoch): 22, Fine-tuning 손실 함수(finetuning_loss): 0.087741\n",
      "반복(Epoch): 23, Fine-tuning 손실 함수(finetuning_loss): 0.166578\n",
      "반복(Epoch): 24, Fine-tuning 손실 함수(finetuning_loss): 0.103171\n",
      "반복(Epoch): 25, Fine-tuning 손실 함수(finetuning_loss): 0.098569\n",
      "반복(Epoch): 26, Fine-tuning 손실 함수(finetuning_loss): 0.061925\n",
      "반복(Epoch): 27, Fine-tuning 손실 함수(finetuning_loss): 0.132937\n",
      "반복(Epoch): 28, Fine-tuning 손실 함수(finetuning_loss): 0.075874\n",
      "반복(Epoch): 29, Fine-tuning 손실 함수(finetuning_loss): 0.095490\n",
      "반복(Epoch): 30, Fine-tuning 손실 함수(finetuning_loss): 0.036683\n",
      "반복(Epoch): 31, Fine-tuning 손실 함수(finetuning_loss): 0.051522\n",
      "반복(Epoch): 32, Fine-tuning 손실 함수(finetuning_loss): 0.097922\n",
      "반복(Epoch): 33, Fine-tuning 손실 함수(finetuning_loss): 0.153627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 34, Fine-tuning 손실 함수(finetuning_loss): 0.033730\n",
      "반복(Epoch): 35, Fine-tuning 손실 함수(finetuning_loss): 0.074498\n",
      "반복(Epoch): 36, Fine-tuning 손실 함수(finetuning_loss): 0.094151\n",
      "반복(Epoch): 37, Fine-tuning 손실 함수(finetuning_loss): 0.042830\n",
      "반복(Epoch): 38, Fine-tuning 손실 함수(finetuning_loss): 0.091360\n",
      "반복(Epoch): 39, Fine-tuning 손실 함수(finetuning_loss): 0.048259\n",
      "반복(Epoch): 40, Fine-tuning 손실 함수(finetuning_loss): 0.111204\n",
      "반복(Epoch): 41, Fine-tuning 손실 함수(finetuning_loss): 0.093989\n",
      "반복(Epoch): 42, Fine-tuning 손실 함수(finetuning_loss): 0.052422\n",
      "반복(Epoch): 43, Fine-tuning 손실 함수(finetuning_loss): 0.133251\n",
      "반복(Epoch): 44, Fine-tuning 손실 함수(finetuning_loss): 0.048688\n",
      "반복(Epoch): 45, Fine-tuning 손실 함수(finetuning_loss): 0.053841\n",
      "반복(Epoch): 46, Fine-tuning 손실 함수(finetuning_loss): 0.065476\n",
      "반복(Epoch): 47, Fine-tuning 손실 함수(finetuning_loss): 0.124366\n",
      "반복(Epoch): 48, Fine-tuning 손실 함수(finetuning_loss): 0.104252\n",
      "반복(Epoch): 49, Fine-tuning 손실 함수(finetuning_loss): 0.036500\n",
      "반복(Epoch): 50, Fine-tuning 손실 함수(finetuning_loss): 0.066531\n",
      "반복(Epoch): 51, Fine-tuning 손실 함수(finetuning_loss): 0.037751\n",
      "반복(Epoch): 52, Fine-tuning 손실 함수(finetuning_loss): 0.101188\n",
      "반복(Epoch): 53, Fine-tuning 손실 함수(finetuning_loss): 0.044957\n",
      "반복(Epoch): 54, Fine-tuning 손실 함수(finetuning_loss): 0.056107\n",
      "반복(Epoch): 55, Fine-tuning 손실 함수(finetuning_loss): 0.035170\n",
      "반복(Epoch): 56, Fine-tuning 손실 함수(finetuning_loss): 0.057302\n",
      "반복(Epoch): 57, Fine-tuning 손실 함수(finetuning_loss): 0.051517\n",
      "반복(Epoch): 58, Fine-tuning 손실 함수(finetuning_loss): 0.039910\n",
      "반복(Epoch): 59, Fine-tuning 손실 함수(finetuning_loss): 0.070777\n",
      "반복(Epoch): 60, Fine-tuning 손실 함수(finetuning_loss): 0.017356\n",
      "반복(Epoch): 61, Fine-tuning 손실 함수(finetuning_loss): 0.036324\n",
      "반복(Epoch): 62, Fine-tuning 손실 함수(finetuning_loss): 0.063439\n",
      "반복(Epoch): 63, Fine-tuning 손실 함수(finetuning_loss): 0.068033\n",
      "반복(Epoch): 64, Fine-tuning 손실 함수(finetuning_loss): 0.045097\n",
      "반복(Epoch): 65, Fine-tuning 손실 함수(finetuning_loss): 0.042126\n",
      "반복(Epoch): 66, Fine-tuning 손실 함수(finetuning_loss): 0.090428\n",
      "반복(Epoch): 67, Fine-tuning 손실 함수(finetuning_loss): 0.027496\n",
      "반복(Epoch): 68, Fine-tuning 손실 함수(finetuning_loss): 0.034208\n",
      "반복(Epoch): 69, Fine-tuning 손실 함수(finetuning_loss): 0.031151\n",
      "반복(Epoch): 70, Fine-tuning 손실 함수(finetuning_loss): 0.034096\n",
      "반복(Epoch): 71, Fine-tuning 손실 함수(finetuning_loss): 0.023227\n",
      "반복(Epoch): 72, Fine-tuning 손실 함수(finetuning_loss): 0.087400\n",
      "반복(Epoch): 73, Fine-tuning 손실 함수(finetuning_loss): 0.047793\n",
      "반복(Epoch): 74, Fine-tuning 손실 함수(finetuning_loss): 0.026324\n",
      "반복(Epoch): 75, Fine-tuning 손실 함수(finetuning_loss): 0.030245\n",
      "반복(Epoch): 76, Fine-tuning 손실 함수(finetuning_loss): 0.073284\n",
      "반복(Epoch): 77, Fine-tuning 손실 함수(finetuning_loss): 0.024187\n",
      "반복(Epoch): 78, Fine-tuning 손실 함수(finetuning_loss): 0.080305\n",
      "반복(Epoch): 79, Fine-tuning 손실 함수(finetuning_loss): 0.081054\n",
      "반복(Epoch): 80, Fine-tuning 손실 함수(finetuning_loss): 0.079416\n",
      "반복(Epoch): 81, Fine-tuning 손실 함수(finetuning_loss): 0.028777\n",
      "반복(Epoch): 82, Fine-tuning 손실 함수(finetuning_loss): 0.022625\n",
      "반복(Epoch): 83, Fine-tuning 손실 함수(finetuning_loss): 0.045834\n",
      "반복(Epoch): 84, Fine-tuning 손실 함수(finetuning_loss): 0.033418\n",
      "반복(Epoch): 85, Fine-tuning 손실 함수(finetuning_loss): 0.025941\n",
      "반복(Epoch): 86, Fine-tuning 손실 함수(finetuning_loss): 0.049693\n",
      "반복(Epoch): 87, Fine-tuning 손실 함수(finetuning_loss): 0.023345\n",
      "반복(Epoch): 88, Fine-tuning 손실 함수(finetuning_loss): 0.034512\n",
      "반복(Epoch): 89, Fine-tuning 손실 함수(finetuning_loss): 0.017879\n",
      "반복(Epoch): 90, Fine-tuning 손실 함수(finetuning_loss): 0.028862\n",
      "반복(Epoch): 91, Fine-tuning 손실 함수(finetuning_loss): 0.029524\n",
      "반복(Epoch): 92, Fine-tuning 손실 함수(finetuning_loss): 0.022276\n",
      "반복(Epoch): 93, Fine-tuning 손실 함수(finetuning_loss): 0.018575\n",
      "반복(Epoch): 94, Fine-tuning 손실 함수(finetuning_loss): 0.070881\n",
      "반복(Epoch): 95, Fine-tuning 손실 함수(finetuning_loss): 0.031320\n",
      "반복(Epoch): 96, Fine-tuning 손실 함수(finetuning_loss): 0.034009\n",
      "반복(Epoch): 97, Fine-tuning 손실 함수(finetuning_loss): 0.022829\n",
      "반복(Epoch): 98, Fine-tuning 손실 함수(finetuning_loss): 0.024141\n",
      "반복(Epoch): 99, Fine-tuning 손실 함수(finetuning_loss): 0.021939\n",
      "반복(Epoch): 100, Fine-tuning 손실 함수(finetuning_loss): 0.023235\n",
      "반복(Epoch): 101, Fine-tuning 손실 함수(finetuning_loss): 0.018144\n",
      "반복(Epoch): 102, Fine-tuning 손실 함수(finetuning_loss): 0.044258\n",
      "반복(Epoch): 103, Fine-tuning 손실 함수(finetuning_loss): 0.024810\n",
      "반복(Epoch): 104, Fine-tuning 손실 함수(finetuning_loss): 0.020564\n",
      "반복(Epoch): 105, Fine-tuning 손실 함수(finetuning_loss): 0.013379\n",
      "반복(Epoch): 106, Fine-tuning 손실 함수(finetuning_loss): 0.018810\n",
      "반복(Epoch): 107, Fine-tuning 손실 함수(finetuning_loss): 0.018302\n",
      "반복(Epoch): 108, Fine-tuning 손실 함수(finetuning_loss): 0.033033\n",
      "반복(Epoch): 109, Fine-tuning 손실 함수(finetuning_loss): 0.011454\n",
      "반복(Epoch): 110, Fine-tuning 손실 함수(finetuning_loss): 0.019268\n",
      "반복(Epoch): 111, Fine-tuning 손실 함수(finetuning_loss): 0.012311\n",
      "반복(Epoch): 112, Fine-tuning 손실 함수(finetuning_loss): 0.031943\n",
      "반복(Epoch): 113, Fine-tuning 손실 함수(finetuning_loss): 0.042020\n",
      "반복(Epoch): 114, Fine-tuning 손실 함수(finetuning_loss): 0.033519\n",
      "반복(Epoch): 115, Fine-tuning 손실 함수(finetuning_loss): 0.022803\n",
      "반복(Epoch): 116, Fine-tuning 손실 함수(finetuning_loss): 0.022780\n",
      "반복(Epoch): 117, Fine-tuning 손실 함수(finetuning_loss): 0.021348\n",
      "반복(Epoch): 118, Fine-tuning 손실 함수(finetuning_loss): 0.016884\n",
      "반복(Epoch): 119, Fine-tuning 손실 함수(finetuning_loss): 0.022575\n",
      "반복(Epoch): 120, Fine-tuning 손실 함수(finetuning_loss): 0.009840\n",
      "반복(Epoch): 121, Fine-tuning 손실 함수(finetuning_loss): 0.025085\n",
      "반복(Epoch): 122, Fine-tuning 손실 함수(finetuning_loss): 0.022804\n",
      "반복(Epoch): 123, Fine-tuning 손실 함수(finetuning_loss): 0.047044\n",
      "반복(Epoch): 124, Fine-tuning 손실 함수(finetuning_loss): 0.044515\n",
      "반복(Epoch): 125, Fine-tuning 손실 함수(finetuning_loss): 0.015784\n",
      "반복(Epoch): 126, Fine-tuning 손실 함수(finetuning_loss): 0.115469\n",
      "반복(Epoch): 127, Fine-tuning 손실 함수(finetuning_loss): 0.024712\n",
      "반복(Epoch): 128, Fine-tuning 손실 함수(finetuning_loss): 0.015088\n",
      "반복(Epoch): 129, Fine-tuning 손실 함수(finetuning_loss): 0.011719\n",
      "반복(Epoch): 130, Fine-tuning 손실 함수(finetuning_loss): 0.014757\n",
      "반복(Epoch): 131, Fine-tuning 손실 함수(finetuning_loss): 0.056962\n",
      "반복(Epoch): 132, Fine-tuning 손실 함수(finetuning_loss): 0.015297\n",
      "반복(Epoch): 133, Fine-tuning 손실 함수(finetuning_loss): 0.018071\n",
      "반복(Epoch): 134, Fine-tuning 손실 함수(finetuning_loss): 0.011823\n",
      "반복(Epoch): 135, Fine-tuning 손실 함수(finetuning_loss): 0.011197\n",
      "반복(Epoch): 136, Fine-tuning 손실 함수(finetuning_loss): 0.024796\n",
      "반복(Epoch): 137, Fine-tuning 손실 함수(finetuning_loss): 0.008463\n",
      "반복(Epoch): 138, Fine-tuning 손실 함수(finetuning_loss): 0.010884\n",
      "반복(Epoch): 139, Fine-tuning 손실 함수(finetuning_loss): 0.009354\n",
      "반복(Epoch): 140, Fine-tuning 손실 함수(finetuning_loss): 0.038850\n",
      "반복(Epoch): 141, Fine-tuning 손실 함수(finetuning_loss): 0.012519\n",
      "반복(Epoch): 142, Fine-tuning 손실 함수(finetuning_loss): 0.021394\n",
      "반복(Epoch): 143, Fine-tuning 손실 함수(finetuning_loss): 0.012694\n",
      "반복(Epoch): 144, Fine-tuning 손실 함수(finetuning_loss): 0.018749\n",
      "반복(Epoch): 145, Fine-tuning 손실 함수(finetuning_loss): 0.005685\n",
      "반복(Epoch): 146, Fine-tuning 손실 함수(finetuning_loss): 0.024228\n",
      "반복(Epoch): 147, Fine-tuning 손실 함수(finetuning_loss): 0.010486\n",
      "반복(Epoch): 148, Fine-tuning 손실 함수(finetuning_loss): 0.020793\n",
      "반복(Epoch): 149, Fine-tuning 손실 함수(finetuning_loss): 0.033275\n",
      "반복(Epoch): 150, Fine-tuning 손실 함수(finetuning_loss): 0.019206\n",
      "반복(Epoch): 151, Fine-tuning 손실 함수(finetuning_loss): 0.010911\n",
      "반복(Epoch): 152, Fine-tuning 손실 함수(finetuning_loss): 0.014569\n",
      "반복(Epoch): 153, Fine-tuning 손실 함수(finetuning_loss): 0.017606\n",
      "반복(Epoch): 154, Fine-tuning 손실 함수(finetuning_loss): 0.008608\n",
      "반복(Epoch): 155, Fine-tuning 손실 함수(finetuning_loss): 0.014207\n",
      "반복(Epoch): 156, Fine-tuning 손실 함수(finetuning_loss): 0.013148\n",
      "반복(Epoch): 157, Fine-tuning 손실 함수(finetuning_loss): 0.013283\n",
      "반복(Epoch): 158, Fine-tuning 손실 함수(finetuning_loss): 0.012488\n",
      "반복(Epoch): 159, Fine-tuning 손실 함수(finetuning_loss): 0.012371\n",
      "반복(Epoch): 160, Fine-tuning 손실 함수(finetuning_loss): 0.036857\n",
      "반복(Epoch): 161, Fine-tuning 손실 함수(finetuning_loss): 0.003614\n",
      "반복(Epoch): 162, Fine-tuning 손실 함수(finetuning_loss): 0.011534\n",
      "반복(Epoch): 163, Fine-tuning 손실 함수(finetuning_loss): 0.011550\n",
      "반복(Epoch): 164, Fine-tuning 손실 함수(finetuning_loss): 0.032806\n",
      "반복(Epoch): 165, Fine-tuning 손실 함수(finetuning_loss): 0.014414\n",
      "반복(Epoch): 166, Fine-tuning 손실 함수(finetuning_loss): 0.030079\n",
      "반복(Epoch): 167, Fine-tuning 손실 함수(finetuning_loss): 0.019640\n",
      "반복(Epoch): 168, Fine-tuning 손실 함수(finetuning_loss): 0.019566\n",
      "반복(Epoch): 169, Fine-tuning 손실 함수(finetuning_loss): 0.005991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 170, Fine-tuning 손실 함수(finetuning_loss): 0.005810\n",
      "반복(Epoch): 171, Fine-tuning 손실 함수(finetuning_loss): 0.015859\n",
      "반복(Epoch): 172, Fine-tuning 손실 함수(finetuning_loss): 0.025053\n",
      "반복(Epoch): 173, Fine-tuning 손실 함수(finetuning_loss): 0.010521\n",
      "반복(Epoch): 174, Fine-tuning 손실 함수(finetuning_loss): 0.021920\n",
      "반복(Epoch): 175, Fine-tuning 손실 함수(finetuning_loss): 0.015217\n",
      "반복(Epoch): 176, Fine-tuning 손실 함수(finetuning_loss): 0.015348\n",
      "반복(Epoch): 177, Fine-tuning 손실 함수(finetuning_loss): 0.039522\n",
      "반복(Epoch): 178, Fine-tuning 손실 함수(finetuning_loss): 0.021278\n",
      "반복(Epoch): 179, Fine-tuning 손실 함수(finetuning_loss): 0.014924\n",
      "반복(Epoch): 180, Fine-tuning 손실 함수(finetuning_loss): 0.014926\n",
      "반복(Epoch): 181, Fine-tuning 손실 함수(finetuning_loss): 0.021195\n",
      "반복(Epoch): 182, Fine-tuning 손실 함수(finetuning_loss): 0.030546\n",
      "반복(Epoch): 183, Fine-tuning 손실 함수(finetuning_loss): 0.009385\n",
      "반복(Epoch): 184, Fine-tuning 손실 함수(finetuning_loss): 0.009882\n",
      "반복(Epoch): 185, Fine-tuning 손실 함수(finetuning_loss): 0.006874\n",
      "반복(Epoch): 186, Fine-tuning 손실 함수(finetuning_loss): 0.007156\n",
      "반복(Epoch): 187, Fine-tuning 손실 함수(finetuning_loss): 0.008236\n",
      "반복(Epoch): 188, Fine-tuning 손실 함수(finetuning_loss): 0.009540\n",
      "반복(Epoch): 189, Fine-tuning 손실 함수(finetuning_loss): 0.013933\n",
      "반복(Epoch): 190, Fine-tuning 손실 함수(finetuning_loss): 0.010455\n",
      "반복(Epoch): 191, Fine-tuning 손실 함수(finetuning_loss): 0.013437\n",
      "반복(Epoch): 192, Fine-tuning 손실 함수(finetuning_loss): 0.012986\n",
      "반복(Epoch): 193, Fine-tuning 손실 함수(finetuning_loss): 0.013143\n",
      "반복(Epoch): 194, Fine-tuning 손실 함수(finetuning_loss): 0.007907\n",
      "반복(Epoch): 195, Fine-tuning 손실 함수(finetuning_loss): 0.015481\n",
      "반복(Epoch): 196, Fine-tuning 손실 함수(finetuning_loss): 0.009645\n",
      "반복(Epoch): 197, Fine-tuning 손실 함수(finetuning_loss): 0.007937\n",
      "반복(Epoch): 198, Fine-tuning 손실 함수(finetuning_loss): 0.010858\n",
      "반복(Epoch): 199, Fine-tuning 손실 함수(finetuning_loss): 0.005206\n",
      "반복(Epoch): 200, Fine-tuning 손실 함수(finetuning_loss): 0.006712\n",
      "Step 2 : MNIST 데이터 분류를 위한 오토인코더+Softmax 분류기 최적화 완료(Fine-Tuning)\n",
      "정확도(오토인코더+Softmax 분류기): 0.966300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "\n",
    "learning_rate_RMSProp = 0.02\n",
    "learning_rate_GradientDescent = 0.5\n",
    "num_epochs = 100         # 반복횟수\n",
    "batch_size = 256\n",
    "display_step = 1         # 몇 Step마다 log를 출력할지 결정합니다.\n",
    "input_size = 784         # MNIST 데이터 input (이미지 크기: 28*28)\n",
    "hidden1_size = 128       # 첫번째 히든레이어의 노드 개수\n",
    "hidden2_size = 64        # 두번째 히든레이어의 노드 개수\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.shuffle(60000).batch(batch_size)\n",
    "\n",
    "class AutoEncoder(object):\n",
    "    def __init__(self):\n",
    "        self.Wh_1 = tf.Variable(tf.random.normal([input_size, hidden1_size]))\n",
    "        self.bh_1 = tf.Variable(tf.random.normal([hidden1_size]))\n",
    "        self.Wh_2 = tf.Variable(tf.random.normal([hidden1_size, hidden2_size]))\n",
    "        self.bh_2 = tf.Variable(tf.random.normal([hidden2_size]))\n",
    "        self.Wh_3 = tf.Variable(tf.random.normal([hidden2_size, hidden1_size]))\n",
    "        self.bh_3 = tf.Variable(tf.random.normal([hidden1_size]))\n",
    "        self.Wo = tf.Variable(tf.random.normal([hidden1_size, input_size]))\n",
    "        self.bo = tf.Variable(tf.random.normal([input_size]))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        H1_output = tf.nn.sigmoid(tf.matmul(x, self.Wh_1) + self.bh_1)\n",
    "        H2_output = tf.nn.sigmoid(tf.matmul(H1_output, self.Wh_2) + self.bh_2)\n",
    "        H3_output = tf.nn.sigmoid(tf.matmul(H2_output, self.Wh_3) + self.bh_3)\n",
    "        X_reconstructed = tf.nn.sigmoid(tf.matmul(H3_output, self.Wo) + self.bo)\n",
    "\n",
    "        return X_reconstructed, H2_output\n",
    "\n",
    "class SoftmaxClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.W_softmax = tf.Variable(tf.zeros([hidden2_size, 10]))  # 원본 MNIST 이미지(784) 대신 오토인코더의 압축된 특징(64)을 입력값으로 받습니다.\n",
    "        self.b_softmax = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y_pred = tf.nn.softmax(tf.matmul(x, self.W_softmax) + self.b_softmax)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "@tf.function\n",
    "def pretraining_mse_loss(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.pow(y_true - y_pred, 2)) # MSE(Mean of Squared Error) 손실함수\n",
    "\n",
    "@tf.function\n",
    "def finetuning_cross_entropy_loss(y_pred_softmax, y):\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y * tf.math.log(y_pred_softmax), axis=[1]))     # cross-entropy loss 함수\n",
    "\n",
    "pretraining_optimizer = tf.optimizers.RMSprop(learning_rate_RMSProp, epsilon=1e-10)\n",
    "@tf.function\n",
    "def pretraining_train_step(autoencoder_model, x):\n",
    "    y_true = x\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred, _ = autoencoder_model(x)\n",
    "        pretraining_loss = pretraining_mse_loss(y_pred, y_true)\n",
    "    gradients = tape.gradient(pretraining_loss, vars(autoencoder_model).values())\n",
    "    pretraining_optimizer.apply_gradients(zip(gradients, vars(autoencoder_model).values()))\n",
    "\n",
    "finetuning_optimizer = tf.optimizers.SGD(learning_rate_GradientDescent)\n",
    "@tf.function\n",
    "def finetuning_train_step(autoencoder_model, softmax_classifier_model, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred, extracted_features = autoencoder_model(x)\n",
    "        y_pred_softmax = softmax_classifier_model(extracted_features)\n",
    "        finetuning_loss = finetuning_cross_entropy_loss(y_pred_softmax, y)\n",
    "    autoencoder_encoding_variables = [autoencoder_model.Wh_1, autoencoder_model.bh_1, autoencoder_model.Wh_2, autoencoder_model.bh_2]\n",
    "    gradients = tape.gradient(finetuning_loss, autoencoder_encoding_variables + list(vars(softmax_classifier_model).values()))\n",
    "    finetuning_optimizer.apply_gradients(zip(gradients, autoencoder_encoding_variables + list(vars(softmax_classifier_model).values())))\n",
    "\n",
    "@tf.function\n",
    "def compute_accuracy(y_pred_softmax, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred_softmax,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "AutoEncoder_model = AutoEncoder()\n",
    "SoftmaxClassifier_model = SoftmaxClassifier()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_x, _ in train_data:\n",
    "        _, pretraining_loss_print = pretraining_train_step(AutoEncoder_model, batch_x), pretraining_mse_loss(AutoEncoder_model(batch_x)[0], batch_x)\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"반복(Epoch): %d, Pre-Training 손실 함수(pretraining_loss): %f\" % ((epoch + 1), pretraining_loss_print))\n",
    "print(\"Step 1 : MNIST 데이터 재구축을 위한 오토인코더 최적화 완료(Pre-Training)\")\n",
    "\n",
    "for epoch in range(num_epochs + 100):\n",
    "    for batch_x, batch_y in train_data:\n",
    "        batch_y = tf.one_hot(batch_y, depth=10)\n",
    "        _, finetuning_loss_print = finetuning_train_step(AutoEncoder_model, SoftmaxClassifier_model, batch_x, batch_y), finetuning_cross_entropy_loss(SoftmaxClassifier_model(AutoEncoder_model(batch_x)[1]), batch_y)\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"반복(Epoch): %d, Fine-tuning 손실 함수(finetuning_loss): %f\" % ((epoch + 1), finetuning_loss_print))\n",
    "print(\"Step 2 : MNIST 데이터 분류를 위한 오토인코더+Softmax 분류기 최적화 완료(Fine-Tuning)\")\n",
    "\n",
    "print(\"정확도(오토인코더+Softmax 분류기): %f\" % compute_accuracy(SoftmaxClassifier_model(AutoEncoder_model(x_test)[1]), tf.one_hot(y_test, depth=10)))  # 정확도 : 약 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
